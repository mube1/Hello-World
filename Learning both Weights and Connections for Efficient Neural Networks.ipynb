{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957c978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7775b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LeNet\n",
    "from eval_model import evaluate_model\n",
    "import mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180d1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf922c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LeNet()\n",
    "# Model class must be defined somewhere\n",
    "model = torch.load('lenet_model')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7cc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epoches=20\n",
    "bs=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb1b9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set=mnist_loader.get_x_and_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564232e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e160771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=evaluate_model(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb5c6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "train=Trainer(model, train, criterion, optimizer, epoches, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d76e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline=result.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc057fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline=int(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266e1530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7eb51de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x7fe72b53bac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e74fa6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_tups = []\n",
    "# for module in model.modules():\n",
    "#     module_tups.append((module, 'weight'))\n",
    "# modules=module_tups[1:]\n",
    "# modules[0].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c312dd43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54e4583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules[0][0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6de7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model_global_unstructured(model, layer_type, proportion):\n",
    "    module_tups = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, layer_type):\n",
    "            module_tups.append((module, 'weight'))\n",
    "\n",
    "    prune.global_unstructured(\n",
    "        parameters=module_tups, pruning_method=prune.L1Unstructured,\n",
    "        amount=proportion\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for module, _ in module_tups:\n",
    "        prune.remove(module, 'weight')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d150ba61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prune_model_global_unstructured() missing 3 required positional arguments: 'model', 'layer_type', and 'proportion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprune_model_global_unstructured\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: prune_model_global_unstructured() missing 3 required positional arguments: 'model', 'layer_type', and 'proportion'"
     ]
    }
   ],
   "source": [
    "prune_model_global_unstructured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f76a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ee27ea9",
   "metadata": {},
   "source": [
    "# https://spell.ml/blog/model-pruning-in-pytorch-X9pXQRAAACIAcH9h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2feee04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countZeroWeights(model):\n",
    "    zeros = 0\n",
    "    for param in model.parameters():\n",
    "        if param is not None:\n",
    "            zeros += torch.sum((param == 0).int()).item()\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "baf400c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59838"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countZeroWeights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e6a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df571151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "torch.Size([6, 1, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 6, 3, 3])\n",
      "torch.Size([120])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([84])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 84])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters() :\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5692ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                       | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate ...  0.1\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█████████████████▌                                                                                                                                                             | 1/10 [00:00<00:07,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.2\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████████████████                                                                                                                                            | 2/10 [00:01<00:05,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.3\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████████████████████████████████▌                                                                                                                          | 3/10 [00:01<00:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.4\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████████████████████████████████████████████                                                                                                         | 4/10 [00:01<00:02,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.5\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 5/10 [00:01<00:02,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.6\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                      | 6/10 [00:02<00:01,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.7\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 7/10 [00:02<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.8\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                   | 8/10 [00:02<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  0.9\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 9/10 [00:02<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n",
      "Rate ...  1.0\n",
      "Non zero/ total ...  60073.0039284882  zeros now : 59838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating new model ...  8.921784356871374 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rates=[.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0]\n",
    "Acc_trace={}\n",
    "\n",
    "for rate in tqdm(rates):\n",
    "    \n",
    "#     prune\n",
    "    modules=[]\n",
    "    \n",
    "    for module in model.modules():\n",
    "        modules.append((module, 'weight'))\n",
    "    \n",
    "    modules=modules[1:]\n",
    "    \n",
    "    print('Rate ... ',rate )\n",
    "    prune.global_unstructured(parameters=modules, pruning_method=prune.L1Unstructured,amount=rate)\n",
    "\n",
    "    zeros=countZeroWeights(model)\n",
    "    \n",
    "    print('Non zero/ total ... ', (total_params-zeros/total_params ), ' zeros now :', zeros)\n",
    "    \n",
    "    for module, _ in modules:\n",
    "        prune.remove(module, 'weight')\n",
    "    \n",
    "    result=evaluate_model(model,test)    \n",
    "\n",
    "    Acc_trace[rate]=result.evaluate()\n",
    "    print('Evaluating new model ... ',list(Acc_trace.values())[-1],'\\n')\n",
    "    \n",
    "#     check accuracy\n",
    "\n",
    "\n",
    "    '''\n",
    "    change mode to train mode\n",
    "        re-train from the existing weights\n",
    "        until accuracy is preserved\n",
    "        \n",
    "        \n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc852cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([96.92938587717543, 96.81936387277456, 94.95899179835968, 91.5483096619324, 79.46589317863572, 76.3252650530106, 67.35347069413882, 31.94638927785557, 12.13242648529706, 8.921784356871374])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc_trace.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b1ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d573465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db48c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b5819da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe712e42cd0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(Acc_trace.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06b87faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)), 'weight')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e539ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.conv1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a02b7c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a55dae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dffcae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                       | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Trainer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/ube/ube/codes/learning both weights and connections/train.py:21\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining\u001b[39m(\u001b[38;5;28mself\u001b[39m, regularization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregularization):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoches)):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set)): \n\u001b[1;32m     23\u001b[0m             images\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Trainer' object is not iterable"
     ]
    }
   ],
   "source": [
    "train.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd2cc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range( epoches):\n",
    "        for i, (images, labels) in enumerate( train_set): \n",
    "            images=images.reshape(-1,1,28,28).float()\n",
    "            outputs =  model(images)   \n",
    "\n",
    "            labels = labels.to( device)        \n",
    "            # Forward pass\n",
    "\n",
    "            loss =  criterion(outputs, labels)\n",
    "\n",
    "\n",
    "\n",
    "      #Replaces pow(2.0) with abs() for L1 regularization\n",
    "\n",
    "#                 l2_lambda = 0.001 hyperparameters\n",
    "#                 l2_norm = sum(p.pow(2.0).sum()\n",
    "#                               for p in model.parameters())\n",
    "\n",
    "#                 loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print (loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71651bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=evaluate_model(model,test)    \n",
    "last=result.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5793701b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.784090151363606"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9b810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aef244a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                       | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Trainer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/ube/ube/codes/learning both weights and connections/train.py:21\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining\u001b[39m(\u001b[38;5;28mself\u001b[39m, regularization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregularization):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoches)):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set)): \n\u001b[1;32m     23\u001b[0m             images\u001b[38;5;241m=\u001b[39mimages\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Trainer' object is not iterable"
     ]
    }
   ],
   "source": [
    "train.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77925d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8500000000000005"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline*.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "010ac474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for epoch in range( epoches):\n",
    "        for i, (images, labels) in enumerate( train_set): \n",
    "            images=images.reshape(-1,1,28,28).float()\n",
    "            outputs =  model(images)   \n",
    "\n",
    "            labels = labels.to( device)        \n",
    "            # Forward pass\n",
    "\n",
    "            loss =  criterion(outputs, labels)\n",
    "\n",
    "\n",
    "\n",
    "      #Replaces pow(2.0) with abs() for L1 regularization\n",
    "\n",
    "#                 l2_lambda = 0.001 hyperparameters\n",
    "#                 l2_norm = sum(p.pow(2.0).sum()\n",
    "#                               for p in model.parameters())\n",
    "\n",
    "#                 loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch : ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b74937f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  2.306302785873413\n",
      "Epoch :  2.3063762187957764\n",
      "Epoch :  2.3064446449279785\n",
      "Epoch :  2.306509256362915\n",
      "Epoch :  2.3065695762634277\n",
      "Epoch :  2.306626558303833\n",
      "Epoch :  2.3066799640655518\n",
      "Epoch :  2.306729793548584\n",
      "Epoch :  2.306776762008667\n",
      "Epoch :  2.30682110786438\n",
      "Epoch :  2.3068623542785645\n",
      "Epoch :  2.306901454925537\n",
      "Epoch :  2.3069381713867188\n",
      "Epoch :  2.3069722652435303\n",
      "Epoch :  2.307004690170288\n",
      "Epoch :  2.307034492492676\n",
      "Epoch :  2.307063102722168\n",
      "Epoch :  2.3070898056030273\n",
      "Epoch :  2.307114362716675\n",
      "Epoch :  2.3071377277374268\n"
     ]
    }
   ],
   "source": [
    "#     return model  \n",
    "accuracy=0\n",
    "bear=5\n",
    "train=Trainer(model, train, criterion, optimizer, epoches, 100)\n",
    "\n",
    "while accuracy <baseline*(bear/100):\n",
    "    \n",
    "    \n",
    "    train_model()    \n",
    "    \n",
    "    \n",
    "#     train\n",
    "#         until accuracy is recovered\n",
    "#     train.training()\n",
    "\n",
    "    #      eval\n",
    "    result=evaluate_model(model,test)  \n",
    "    accuracy=result.evaluate()\n",
    "#     Acc_trace[rate]=result.evaluate()\n",
    "\n",
    "\n",
    "#     check percentage of prunned\n",
    "    \n",
    "#     if done break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7d1f6e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model=evaluate_model(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b165ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=eval_model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb8c16de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.352270454090819"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9a103f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bias',\n",
       "              tensor([ 0.0322, -0.1876, -0.0309,  0.1002,  0.0660, -0.1587])),\n",
       "             ('weight',\n",
       "              tensor([[[[-1.9875e-17, -2.0083e-17, -2.1958e-17],\n",
       "                        [-2.3534e-17, -2.4027e-17, -2.6104e-17],\n",
       "                        [-2.7412e-17, -2.7924e-17, -3.0297e-17]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "                        [-0.0000e+00, -0.0000e+00, -0.0000e+00]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
       "                        [-0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "                        [-0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1803e-17, -6.2451e-17, -6.8279e-17],\n",
       "                        [-7.3182e-17, -7.4714e-17, -8.1173e-17],\n",
       "                        [-8.5239e-17, -8.6831e-17, -9.4212e-17]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0688e-17, -4.1115e-17, -4.4953e-17],\n",
       "                        [-4.8180e-17, -4.9189e-17, -5.3442e-17],\n",
       "                        [-5.6118e-17, -5.7167e-17, -6.2025e-17]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "                        [ 0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "                        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]]))])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules[0][0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5134cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
